{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../cleaned_data_json/sample_cross.json\") as f:\n",
    "    data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scispacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_sci_lg\") #biomedical specially trained model knows stop words of medical language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merged abstract and body-text of a paper as doc\n",
    "text = [i[\"abstract\"].lower()+\" \"+i[\"body_text\"].lower() for i in data[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL DOCS :  2000\n"
     ]
    }
   ],
   "source": [
    "#Took 2000 Research Papers for modelling\n",
    "cleaned_data = text\n",
    "print(\"TOTAL DOCS : \", len(cleaned_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SPACY CAN CONSOLIDATE ALL OF THE TEXT CLEANING OPERATIONS UNDER ONE LINE \"\"\"\n",
    "\"\"\"THIS TAKES A TEXT AS INPUT TOKENIZES IT AND THEN DISCARDS THE TOKENS IF THEY BELONG TO\"\"\" \n",
    "\"\"\"PUNCTUATIONS STOP WORDS URLS EMAILS\"\"\"\n",
    "tokens_data = [[token.lower_ for token in nlp.tokenizer(cd) if not token.is_punct and not token.is_stop and not token.is_space and not token.like_url and not token.like_email] for cd in cleaned_data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking stops_words\n",
    "tokens_data_pool = [t for tokens in tokens_data for t in tokens]\n",
    "from collections import Counter\n",
    "wrds = Counter(tokens_data_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_found = \"preprint license copyright author/funder word count text https doi figure holder data cases medrxiv biorxiv made time may study high total population number granted used using also international fig cc-by-nc-nd rights reserved peer-reviewed et al. medrxiv copyright auther/funder copyright copyrights pre print preprint = fig fig. figure \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "\"This is the problem with stop_words_found also called bekar even when the word is not present it will signal as if it's there.\"\n",
    "if \"pre\" in stop_words_found:\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_found = stop_words_found.split() #Best way to keep stop words\n",
    "tokens_data = [[token for token in td if token not in stop_words_found] for td in tokens_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "#After splitting and converting into list it works as thought.\n",
    "if \"pre\" in stop_words_found:\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199244\n"
     ]
    }
   ],
   "source": [
    "# Fitted LDA\n",
    "from gensim import models, corpora\n",
    "NUM_TOPICS=10\n",
    "dictionary = corpora.Dictionary(tokens_data)\n",
    "print(len(dictionary))\n",
    "corpus = [dictionary.doc2bow(t) for t in tokens_data]\n",
    "lda_model = models.LdaModel(corpus=corpus, num_topics=NUM_TOPICS, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0: 0.004*\"cells\" + 0.004*\"patients\" + 0.004*\"2\" + 0.004*\"de\" + 0.004*\"1\" + 0.003*\"viral\" + 0.003*\"cell\" + 0.003*\"virus\" + 0.003*\"3\" + 0.003*\"protein\" + 0.002*\"infection\" + 0.002*\"t\" + 0.002*\"different\" + 0.002*\"c\" + 0.002*\"table\" + 0.002*\"s\" + 0.002*\"disease\" + 0.002*\"analysis\" + 0.002*\"p\" + 0.002*\"5\" + 0.002*\"clinical\" + 0.002*\"control\" + 0.002*\"4\" + 0.002*\"rna\" + 0.002*\"e\" + 0.002*\"results\" + 0.002*\"la\" + 0.002*\"infected\" + 0.001*\"n\" + 0.001*\"+\" + 0.001*\"model\" + 0.001*\"gene\" + 0.001*\"respiratory\" + 0.001*\"patient\" + 0.001*\"en\" + 0.001*\"expression\" + 0.001*\"group\" + 0.001*\"10\" + 0.001*\"human\" + 0.001*\"viruses\" + 0.001*\"reported\" + 0.001*\"associated\" + 0.001*\"available\" + 0.001*\"use\" + 0.001*\"health\" + 0.001*\"system\" + 0.001*\"proteins\" + 0.001*\"h\" + 0.001*\"performed\" + 0.001*\"care\"\n",
      "\n",
      "Topic #1: 0.004*\"virus\" + 0.004*\"1\" + 0.003*\"2\" + 0.003*\"infection\" + 0.003*\"5\" + 0.003*\"human\" + 0.002*\"disease\" + 0.002*\"4\" + 0.002*\"viral\" + 0.002*\"3\" + 0.002*\"cell\" + 0.002*\"patients\" + 0.002*\"cells\" + 0.002*\"de\" + 0.002*\"c\" + 0.002*\"viruses\" + 0.002*\"available\" + 0.002*\"protein\" + 0.002*\"control\" + 0.002*\"la\" + 0.002*\"studies\" + 0.002*\"table\" + 0.002*\"case\" + 0.002*\"reported\" + 0.002*\"group\" + 0.002*\"model\" + 0.002*\"influenza\" + 0.001*\"samples\" + 0.001*\"days\" + 0.001*\"respiratory\" + 0.001*\"risk\" + 0.001*\"analysis\" + 0.001*\"rna\" + 0.001*\"rate\" + 0.001*\"found\" + 0.001*\"compared\" + 0.001*\"significant\" + 0.001*\"10\" + 0.001*\"des\" + 0.001*\"results\" + 0.001*\"different\" + 0.001*\"treatment\" + 0.001*\"new\" + 0.001*\"use\" + 0.001*\"sequence\" + 0.001*\"including\" + 0.001*\"clinical\" + 0.001*\"immune\" + 0.001*\"gene\" + 0.001*\"observed\"\n",
      "\n",
      "Topic #2: 0.006*\"patients\" + 0.005*\"1\" + 0.005*\"cells\" + 0.004*\"virus\" + 0.004*\"disease\" + 0.003*\"viral\" + 0.003*\"2\" + 0.003*\"infection\" + 0.003*\"covid-19\" + 0.003*\"3\" + 0.003*\"protein\" + 0.002*\"results\" + 0.002*\"analysis\" + 0.002*\"clinical\" + 0.002*\"4\" + 0.002*\"respiratory\" + 0.002*\"cell\" + 0.002*\"found\" + 0.002*\"studies\" + 0.002*\"human\" + 0.002*\"expression\" + 0.002*\"5\" + 0.002*\"t\" + 0.002*\"c\" + 0.002*\"system\" + 0.002*\"treatment\" + 0.002*\"available\" + 0.002*\"different\" + 0.002*\"10\" + 0.002*\"infections\" + 0.002*\"reported\" + 0.002*\"infected\" + 0.002*\"group\" + 0.002*\"rate\" + 0.002*\"health\" + 0.002*\"viruses\" + 0.002*\"samples\" + 0.002*\"shown\" + 0.002*\"compared\" + 0.002*\"model\" + 0.002*\"sars-cov-2\" + 0.001*\"associated\" + 0.001*\"response\" + 0.001*\"rna\" + 0.001*\"table\" + 0.001*\"showed\" + 0.001*\"vaccine\" + 0.001*\"levels\" + 0.001*\"proteins\" + 0.001*\"risk\"\n",
      "\n",
      "Topic #3: 0.005*\"1\" + 0.004*\"virus\" + 0.004*\"2\" + 0.004*\"infection\" + 0.004*\"cells\" + 0.004*\"viral\" + 0.003*\"rna\" + 0.003*\"protein\" + 0.002*\"covid-19\" + 0.002*\"3\" + 0.002*\"cell\" + 0.002*\"10\" + 0.002*\"c\" + 0.002*\"samples\" + 0.002*\"de\" + 0.002*\"4\" + 0.002*\"proteins\" + 0.002*\"different\" + 0.002*\"table\" + 0.002*\"5\" + 0.002*\"la\" + 0.002*\"available\" + 0.002*\"expression\" + 0.002*\"studies\" + 0.002*\"results\" + 0.002*\"reported\" + 0.002*\"health\" + 0.002*\"control\" + 0.002*\"case\" + 0.001*\"found\" + 0.001*\"disease\" + 0.001*\"infected\" + 0.001*\"analysis\" + 0.001*\"viruses\" + 0.001*\"including\" + 0.001*\"days\" + 0.001*\"human\" + 0.001*\"based\" + 0.001*\"model\" + 0.001*\"rate\" + 0.001*\"p\" + 0.001*\"shown\" + 0.001*\"b\" + 0.001*\"patients\" + 0.001*\"6\" + 0.001*\"system\" + 0.001*\"genes\" + 0.001*\"infections\" + 0.001*\"t\" + 0.001*\"activity\"\n",
      "\n",
      "Topic #4: 0.005*\"cells\" + 0.004*\"1\" + 0.004*\"2\" + 0.004*\"virus\" + 0.003*\"infection\" + 0.003*\"disease\" + 0.003*\"protein\" + 0.003*\"covid-19\" + 0.003*\"3\" + 0.003*\"patients\" + 0.003*\"viral\" + 0.003*\"cell\" + 0.003*\"t\" + 0.002*\"q\" + 0.002*\"e\" + 0.002*\"analysis\" + 0.002*\"r\" + 0.002*\"studies\" + 0.002*\"results\" + 0.002*\"c\" + 0.002*\"different\" + 0.002*\"n\" + 0.002*\"infected\" + 0.002*\"expression\" + 0.002*\"available\" + 0.002*\"found\" + 0.002*\"6\" + 0.002*\"10\" + 0.002*\"s\" + 0.002*\"mice\" + 0.002*\"model\" + 0.002*\"human\" + 0.002*\"viruses\" + 0.002*\"samples\" + 0.002*\"h\" + 0.002*\"p\" + 0.002*\"control\" + 0.002*\"group\" + 0.002*\"shown\" + 0.001*\"rna\" + 0.001*\"4\" + 0.001*\"transmission\" + 0.001*\"activity\" + 0.001*\"display\" + 0.001*\"health\" + 0.001*\"observed\" + 0.001*\"5\" + 0.001*\"table\" + 0.001*\"respiratory\" + 0.001*\"clinical\"\n",
      "\n",
      "Topic #5: 0.006*\"cells\" + 0.006*\"1\" + 0.005*\"de\" + 0.004*\"infection\" + 0.004*\"2\" + 0.004*\"virus\" + 0.003*\"3\" + 0.003*\"protein\" + 0.003*\"patients\" + 0.003*\"viruses\" + 0.003*\"cell\" + 0.003*\"10\" + 0.002*\"viral\" + 0.002*\"la\" + 0.002*\"5\" + 0.002*\"c\" + 0.002*\"clinical\" + 0.002*\"model\" + 0.002*\"4\" + 0.002*\"human\" + 0.002*\"le\" + 0.002*\"covid-19\" + 0.002*\"des\" + 0.002*\"days\" + 0.002*\"health\" + 0.002*\"observed\" + 0.002*\"table\" + 0.002*\"different\" + 0.002*\"treatment\" + 0.002*\"disease\" + 0.001*\"analysis\" + 0.001*\"Ã \" + 0.001*\"samples\" + 0.001*\"available\" + 0.001*\"results\" + 0.001*\"t\" + 0.001*\"respiratory\" + 0.001*\"activity\" + 0.001*\"rna\" + 0.001*\"studies\" + 0.001*\"les\" + 0.001*\"s\" + 0.001*\"including\" + 0.001*\"p\" + 0.001*\"response\" + 0.001*\"7\" + 0.001*\"showed\" + 0.001*\"significant\" + 0.001*\"expression\" + 0.001*\"infected\"\n",
      "\n",
      "Topic #6: 0.006*\"q\" + 0.005*\"1\" + 0.005*\"cells\" + 0.004*\"virus\" + 0.004*\"infection\" + 0.003*\"2\" + 0.003*\"protein\" + 0.003*\"viral\" + 0.003*\"5\" + 0.002*\"patients\" + 0.002*\"viruses\" + 0.002*\"infected\" + 0.002*\"cell\" + 0.002*\"3\" + 0.002*\"rna\" + 0.002*\"disease\" + 0.002*\"studies\" + 0.002*\"4\" + 0.002*\"model\" + 0.002*\"influenza\" + 0.002*\"human\" + 0.002*\"10\" + 0.002*\"results\" + 0.002*\"n\" + 0.002*\"reported\" + 0.002*\"treatment\" + 0.002*\"t\" + 0.002*\"including\" + 0.002*\"c\" + 0.002*\"de\" + 0.001*\"la\" + 0.001*\"p\" + 0.001*\"samples\" + 0.001*\"different\" + 0.001*\"expression\" + 0.001*\"control\" + 0.001*\"clinical\" + 0.001*\"performed\" + 0.001*\"b\" + 0.001*\"available\" + 0.001*\"6\" + 0.001*\"days\" + 0.001*\"showed\" + 0.001*\"activity\" + 0.001*\"found\" + 0.001*\"response\" + 0.001*\"associated\" + 0.001*\"levels\" + 0.001*\"health\" + 0.001*\"analysis\"\n",
      "\n",
      "Topic #7: 0.006*\"cells\" + 0.005*\"virus\" + 0.004*\"viral\" + 0.004*\"1\" + 0.004*\"2\" + 0.004*\"infection\" + 0.003*\"viruses\" + 0.002*\"health\" + 0.002*\"3\" + 0.002*\"patients\" + 0.002*\"protein\" + 0.002*\"control\" + 0.002*\"analysis\" + 0.002*\"cell\" + 0.002*\"model\" + 0.002*\"4\" + 0.002*\"disease\" + 0.002*\"proteins\" + 0.002*\"10\" + 0.002*\"different\" + 0.002*\"5\" + 0.002*\"respiratory\" + 0.002*\"c\" + 0.002*\"observed\" + 0.002*\"human\" + 0.002*\"results\" + 0.002*\"rna\" + 0.002*\"group\" + 0.002*\"expression\" + 0.002*\"studies\" + 0.002*\"infected\" + 0.002*\"Â°\" + 0.002*\"t\" + 0.001*\"samples\" + 0.001*\"reported\" + 0.001*\"significant\" + 0.001*\"table\" + 0.001*\"found\" + 0.001*\"rate\" + 0.001*\"replication\" + 0.001*\"covid-19\" + 0.001*\"higher\" + 0.001*\"p\" + 0.001*\"including\" + 0.001*\"6\" + 0.001*\"showed\" + 0.001*\"days\" + 0.001*\"system\" + 0.001*\"based\" + 0.001*\"clinical\"\n",
      "\n",
      "Topic #8: 0.061*\"q\" + 0.005*\"1\" + 0.003*\"2\" + 0.003*\"infection\" + 0.003*\"cells\" + 0.003*\"virus\" + 0.002*\"t\" + 0.002*\"3\" + 0.002*\"viral\" + 0.002*\"e\" + 0.002*\"5\" + 0.002*\"n\" + 0.002*\"model\" + 0.002*\"de\" + 0.002*\"different\" + 0.002*\"results\" + 0.002*\"table\" + 0.002*\"10\" + 0.002*\"c\" + 0.002*\"available\" + 0.002*\"patients\" + 0.002*\"4\" + 0.002*\"covid-19\" + 0.002*\"studies\" + 0.002*\"reported\" + 0.002*\"protein\" + 0.002*\"r\" + 0.002*\"analysis\" + 0.002*\"cell\" + 0.001*\"disease\" + 0.001*\"b\" + 0.001*\"s\" + 0.001*\"compared\" + 0.001*\"found\" + 0.001*\"proteins\" + 0.001*\"0\" + 0.001*\"shown\" + 0.001*\"display\" + 0.001*\"p\" + 0.001*\"sequence\" + 0.001*\"infected\" + 0.001*\"perpetuity\" + 0.001*\"rate\" + 0.001*\"health\" + 0.001*\"observed\" + 0.001*\"use\" + 0.001*\"human\" + 0.001*\"based\" + 0.001*\"identified\" + 0.001*\"6\"\n",
      "\n",
      "Topic #9: 0.005*\"de\" + 0.004*\"1\" + 0.004*\"2\" + 0.003*\"cells\" + 0.003*\"virus\" + 0.003*\"la\" + 0.003*\"patients\" + 0.002*\"viral\" + 0.002*\"results\" + 0.002*\"model\" + 0.002*\"infection\" + 0.002*\"cell\" + 0.002*\"5\" + 0.002*\"reported\" + 0.002*\"disease\" + 0.002*\"3\" + 0.002*\"health\" + 0.002*\"protein\" + 0.002*\"10\" + 0.002*\"different\" + 0.002*\"t\" + 0.002*\"viruses\" + 0.002*\"human\" + 0.002*\"samples\" + 0.002*\"c\" + 0.002*\"days\" + 0.002*\"analysis\" + 0.001*\"available\" + 0.001*\"n\" + 0.001*\"studies\" + 0.001*\"proteins\" + 0.001*\"found\" + 0.001*\"including\" + 0.001*\"table\" + 0.001*\"rate\" + 0.001*\"respiratory\" + 0.001*\"p\" + 0.001*\"use\" + 0.001*\"clinical\" + 0.001*\"en\" + 0.001*\"les\" + 0.001*\"infected\" + 0.001*\"le\" + 0.001*\"observed\" + 0.001*\"infections\" + 0.001*\"group\" + 0.001*\"transmission\" + 0.001*\"rna\" + 0.001*\"covid-19\" + 0.001*\"based\"\n"
     ]
    }
   ],
   "source": [
    "for idx in range(NUM_TOPICS):\n",
    "    print(\"\\nTopic #%s:\" % idx, lda_model.print_topic(idx, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papertopic={}\n",
    "for i,t in enumerate(tokens_data):\n",
    "    result=lda_model[dictionary.doc2bow(tokens_data[i])]\n",
    "    maxresult=result[0][1]\n",
    "    for j in result:\n",
    "        if j[1]>maxresult:\n",
    "            maxresult=j[1]\n",
    "    topic=[j[0] for j in result if j[1]==maxresult][0]\n",
    "    papertopic[str(i)]=topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq=[j for j in papertopic.values()]\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.countplot(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topic(p,topic_num):\n",
    "    topic=[]\n",
    "    for i in p.keys():\n",
    "        if p[i]==topic_num:\n",
    "            topic.append(int(i))\n",
    "    return topic\n",
    "topic0=extract_topic(papertopic,0)\n",
    "topic1=extract_topic(papertopic,1)\n",
    "topic2=extract_topic(papertopic,2)\n",
    "topic3=extract_topic(papertopic,3)\n",
    "topic4=extract_topic(papertopic,4)\n",
    "topic5=extract_topic(papertopic,5)\n",
    "topic6=extract_topic(papertopic,6)\n",
    "topic7=extract_topic(papertopic,7)\n",
    "topic8=extract_topic(papertopic,8)\n",
    "topic9=extract_topic(papertopic,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here i have tried to make heading from paper Title in those topic+common words in those topic\n",
    "paper_topic1=[data['text'][i][\"title\"] for i in topic1]\n",
    "paper_topic5=[data['text'][i][\"title\"] for i in topic5]\n",
    "print(\"Most Common words:\",lda_model.print_topic(1, 50))\n",
    "print(\"\\nPaper Catogarized in this topic\")\n",
    "for i in paper_topic1:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtopic(topic1,NUM_TOPICS):\n",
    "    topic1_data=[tokens_data[i] for i in topic1]\n",
    "    topic1_tokenized=[]\n",
    "    for i in topic1_data:\n",
    "        topic1_tokenized.append(tokens_data[i])\n",
    "    dictionary = corpora.Dictionary(topic1_tokenized)\n",
    "    print(len(dictionary))\n",
    "    corpus = [dictionary.doc2bow(t) for t in topic1_tokenized]\n",
    "    model_topic1 = models.LdaModel(corpus=corpus, num_topics=NUM_TOPICS, id2word=dictionary)\n",
    "\n",
    "    papertopic1={}\n",
    "    for i,t in enumerate(topic1_data):\n",
    "        result=model_topic1[dictionary.doc2bow(tokens_data[i])]\n",
    "        maxresult=result[0][1]\n",
    "        for j in result:\n",
    "            if j[1]>maxresult:\n",
    "                maxresult=j[1]\n",
    "        topic=[j[0] for j in result if j[1]==maxresult][0]\n",
    "        papertopic1[str(i)]=topic\n",
    "    return papertopic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(20,20))\n",
    "# f, axes = plt.subplots(2, 5,figsize=(20,10))\n",
    "# axes[0][0].title.set_text('SubTopics Under Topic 0')\n",
    "# axes[0][1].title.set_text('SubTopics Under Topic 1')\n",
    "# axes[0][2].title.set_text('SubTopics Under Topic 2')\n",
    "# axes[0][3].title.set_text('SubTopics Under Topic 3')\n",
    "# axes[0][4].title.set_text('SubTopics Under Topic 4')\n",
    "# axes[1][0].title.set_text('SubTopics Under Topic 5')\n",
    "# axes[1][1].title.set_text('SubTopics Under Topic 6')\n",
    "# axes[1][2].title.set_text('SubTopics Under Topic 7')\n",
    "# axes[1][3].title.set_text('SubTopics Under Topic 8')\n",
    "# axes[1][4].title.set_text('SubTopics Under Topic 9')\n",
    "# sns.countplot([j for j in subtopic(topic0,5).values()],ax=axes[0][0])\n",
    "# sns.countplot([j for j in subtopic(topic1,5).values()],ax=axes[0][1])\n",
    "# sns.countplot([j for j in subtopic(topic2,5).values()],ax=axes[0][2])\n",
    "# sns.countplot([j for j in subtopic(topic3,5).values()],ax=axes[0][3])\n",
    "# sns.countplot([j for j in subtopic(topic4,5).values()],ax=axes[0][4])\n",
    "# sns.countplot([j for j in subtopic(topic5,5).values()],ax=axes[1][0])\n",
    "# sns.countplot([j for j in subtopic(topic6,5).values()],ax=axes[1][1])\n",
    "# sns.countplot([j for j in subtopic(topic7,5).values()],ax=axes[1][2])\n",
    "# sns.countplot([j for j in subtopic(topic8,5).values()],ax=axes[1][3])\n",
    "# sns.countplot([j for j in subtopic(topic9,5).values()],ax=axes[1][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
