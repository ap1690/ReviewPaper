{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import scispacy\n",
    "import spacy\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../cleaned_data_json/sample.json\") as f:\n",
    "    data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merged abstract and body-text of a paper as doc\n",
    "text_data = [dt[\"abstract\"].lower() for dt in data[\"text\"] if dt['abstract']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL DOCS :  1774\n"
     ]
    }
   ],
   "source": [
    "#Took 2000 Research Papers for modelling\n",
    "print(\"TOTAL DOCS : \", len(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "def remove_accent_chars(text):\n",
    "    text = unicodedata.normalize('NFKD',text).encode('ascii','ignore').decode('utf-8','ignore')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    \"\"\"This takes text as input and then finds whether each character is not a-z A-Z 0-9 and replaces them with nothing \"\"\"\n",
    "    pattern = r'[^a-zA-z\\s]' if remove_digits else r'[^0-9a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_found = \"preprint license copyright author/funder word count text https doi figure holder data cases medrxiv biorxiv made time may study high total population number granted used using also international fig cc-by-nc-nd rights reserved peer-reviewed et al. medrxiv copyright auther/funder copyright copyrights pre print preprint = fig fig. figure \"\n",
    "stop_words_found = stop_words_found.split() #Best way to keep stop words\n",
    "stop_words_found.extend([\"abstract\",\"perpetuity\",\"authorfunder\",\"license\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(doc):\n",
    "    return \" \".join(map(str.lower,(map(str,([token.lemma_ for token in doc if not token.is_stop and not token.is_space and not token.is_punct and not token.like_url and not token.like_email and token.text not in stop_words_found])))))\n",
    "nlp = spacy.load(\"en_core_sci_sm\", disable = ['tagger', 'parser','ner'], max_length=2000000)\n",
    "nlp.add_pipe(cleaner,name=\"cleaner\",first=True)\n",
    "nlp.add_pipe(remove_accent_chars,name='accent_char_removal',after='cleaner')\n",
    "nlp.add_pipe(remove_special_characters,name='remove_special_char',after='accent_char_removal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data_cleaned = list(nlp.pipe(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'194 22 5168 23 24 25 reuse allow permission 27 positive strand rna genome picornaviruses comprise single large open read 28 frame flank 5 3 untranslated region utrs footandmouth disease virus fmdv 29 unusually large 5 utr 13 kb contain structural domain include 30 internal ribosome entry site ires facilitate initiation translation cisacting 31 replication element cre characterise structure 5 terminal 360 nucleotide 32 stemloop variable length polyctract approximately 100 200 nucleotide series 33 tandemly repeat pseudoknots pk investigate structure pk 34 selective 2 hydroxyl acetylation analyse primer extension shape analysis 35 determine contribution genome replication mutation deletion experiment 36 shape mutation experiment confirm importance previously predict pk 37 structure function deletion experiment show pk essential 38 replication provide genome competitive advantage 39 replicons fulllength genome lack pk replication competent infectious 40 virus rescue genome contain pk copy consistent 41 early report describe presence putative package signal pk region 42 43 reuse allow permission'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_cleaned[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Getting Top n-grams from corpus\"\"\"\n",
    "def flatten_corpus(corpus):\n",
    "    return \" \".join([d.strip() for d in corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_grams(corpus,ngram_val=1,limit=10):\n",
    "    text_data_flatten = flatten_corpus(corpus)\n",
    "    tokens = [token.text for token in nlp.tokenizer(text_data_flatten)]\n",
    "    ngrams = compute_ngrams(tokens, ngram_val)\n",
    "    ngrams_freq_dist = nltk.FreqDist(ngrams)\n",
    "    sorted_ngrams_fd = sorted(ngrams_freq_dist.items(),key=itemgetter(1), reverse=True)\n",
    "    sorted_ngrams = sorted_ngrams_fd[0:limit]\n",
    "    sorted_ngrams = [(' '.join(text), freq) for text, freq in sorted_ngrams]\n",
    "    return sorted_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('95 ci', 139),\n",
       " ('public health', 131),\n",
       " ('reuse allow', 128),\n",
       " ('allow permission', 128),\n",
       " ('acute respiratory', 107),\n",
       " ('respiratory syndrome', 105),\n",
       " ('severe acute', 87),\n",
       " ('novel coronavirus', 86),\n",
       " ('infectious disease', 79),\n",
       " ('covid19 pandemic', 74),\n",
       " ('covid19 patient', 73),\n",
       " ('immune response', 72),\n",
       " ('coronavirus disease', 72),\n",
       " ('rna virus', 68),\n",
       " ('s protein', 67),\n",
       " ('amino acid', 67),\n",
       " ('40 available', 66),\n",
       " ('viral infection', 62),\n",
       " ('t cell', 60),\n",
       " ('influenza virus', 59)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_grams(text_data_cleaned,ngram_val=2,limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reuse allow permission', 128),\n",
       " ('severe acute respiratory', 82),\n",
       " ('acute respiratory syndrome', 72),\n",
       " ('allow permission display', 55),\n",
       " ('coronavirus disease 2019', 52),\n",
       " ('respiratory syndrome coronavirus', 50),\n",
       " ('40 available display', 46),\n",
       " ('middle east respiratory', 29),\n",
       " ('ccby 40 available', 28),\n",
       " ('east respiratory syndrome', 27),\n",
       " ('coronavirus 2 sarscov2', 25),\n",
       " ('polymerase chain reaction', 24),\n",
       " ('respiratory syndrome sars', 23),\n",
       " ('respiratory tract infection', 23),\n",
       " ('intensive care unit', 22),\n",
       " ('novel coronavirus 2019ncov', 21),\n",
       " ('disease 2019 covid19', 21),\n",
       " ('public health emergency', 21),\n",
       " ('syndrome coronavirus 2', 21),\n",
       " ('novel coronavirus sarscov2', 20)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_grams(text_data_cleaned,ngram_val=3,limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "text_data_flatten = flatten_corpus(text_data_cleaned)\n",
    "search = '95 ci'\n",
    "print(len(search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 95 ci 144 214 346 95 ci 281 417 scenario asymp\n",
      "5 ci 12 21and hr 23 95 ci 16 32 respectively arr\n",
      "5 95 ci 12 19 hr 18 95 ci 13 25 respectively dem\n",
      "vely dementia hr 12 95 ci 09 18 hr 18 95 ci 11 2\n",
      "3 95 ci 10 17 hr 17 95 ci 12 25 respectively dia\n",
      "vely diabetes hr 15 95 ci 13 19 hr 16 95 ci 11 2\n",
      "4 95 ci 12 26 hr 16 95 ci 12 21 respectively cop\n",
      "i 14 25 death hr 11 95 ci 07 17 previous use ace\n",
      "sessment score sofa 95 ci 1374 2860 p  0001 whit\n",
      "d 21 r0 estimate 44 95 ci 39 49 generalize growt\n",
      "usehold contact 136 95 ci 47 295 nonhousehold fa\n",
      "cvd hypertension 44 95 ci 264 747 37 95 ci 222 5\n",
      " saturation  88 699 95 ci 45 110 ddimer2500 69 9\n",
      "2 admission hr 0704 95 ci 0546 0909 1 decrease p\n",
      "uctive drop 232 076 95 ci 066 086 infect case es\n",
      "p0012 ct value 0158 95 ci 0025 0987 p0048 pii 19\n",
      "ial hospital hr 073 95 ci 054 099 illness hr 066\n",
      "io low midlands 111 95 ci 107 114 high north eas\n",
      "n difference 424 gl 95 ci 620 228 p0001 associat\n",
      "eral involvement 84 95 ci 081 088 commonly invol\n",
      "tial ct examination 95 ci weight conduct subgrou\n",
      "ptt  66 second 1428 95 ci 328 6224 sodium 130 mm\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(text_data_flatten),5):\n",
    "    if text_data_flatten[i:i+5] == search:\n",
    "        print(text_data_flatten[i-20:i+28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POINTWISE MUTUAL INFORMATION'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"POINTWISE MUTUAL INFORMATION\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import BigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token.text for token in nlp.tokenizer(text_data_flatten)]\n",
    "finder = BigramCollocationFinder.from_documents([tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('95', 'ci'),\n",
       " ('public', 'health'),\n",
       " ('allow', 'permission'),\n",
       " ('reuse', 'allow'),\n",
       " ('acute', 'respiratory'),\n",
       " ('respiratory', 'syndrome'),\n",
       " ('severe', 'acute'),\n",
       " ('novel', 'coronavirus'),\n",
       " ('infectious', 'disease'),\n",
       " ('covid19', 'pandemic')]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_measures = BigramAssocMeasures()\n",
    "finder.nbest(bigram_measures.raw_freq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('00049', '254'),\n",
       " ('0042', '0078'),\n",
       " ('0067', '0105'),\n",
       " ('0069', '0707'),\n",
       " ('0076', '0473'),\n",
       " ('0079', 's1a'),\n",
       " ('0102', '0982'),\n",
       " ('0165', '24279505520'),\n",
       " ('0167', '5877950950'),\n",
       " ('0176', '3098')]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.nbest(bigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.collocations import TrigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0069', '0707', 'p0011'),\n",
       " ('05ml', 'intra', '025ml'),\n",
       " ('0987', 'p0048', 'pii'),\n",
       " ('11525', '24053', '240167'),\n",
       " ('1187', '3079', 'p0008'),\n",
       " ('1206', '4580', 'p0012'),\n",
       " ('1279', '92927', 'p0029'),\n",
       " ('1354', '648', '2091'),\n",
       " ('13[12', 'inappetence', '11[10'),\n",
       " ('143173', '647', '112173')]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder = TrigramCollocationFinder.from_documents([tokens])\n",
    "trigram_measures = TrigramAssocMeasures()\n",
    "finder.nbest(trigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = spacy.load(\"en_core_sci_sm\")\n",
    "def get_tfidf_key_phrases(text_data_cleaned,top_n=10):\n",
    "    text_noun_phrases = []\n",
    "    for tdc in text_data_cleaned:\n",
    "        noun_phrase = []\n",
    "        for np in tokenizer(tdc).noun_chunks:\n",
    "            noun_phrase.append(np.text)\n",
    "        text_noun_phrases.append(noun_phrase)\n",
    "    dictionary = corpora.Dictionary(text_noun_phrases)\n",
    "    corpus = [dictionary.doc2bow(chunk) for chunk in text_noun_phrases]\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    weighted_phrases = {dictionary.get(idx): value for doc in corpus_tfidf for idx, value in doc}\n",
    "    weighted_phrases = sorted(weighted_phrases.items(),key=itemgetter(1), reverse=True)\n",
    "    weighted_phrases = [(term, round(wt, 3)) for term, wt in weighted_phrases]\n",
    "    return weighted_phrases[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pulmonary sample individual', 1.0),\n",
       " ('word', 1.0),\n",
       " ('covid19 sarscov2', 1.0),\n",
       " ('reliable estimate covid19 mortality crucial aid control strategy assess effectiveness intervention',\n",
       "  1.0),\n",
       " ('motivation dna metabarcoding com', 1.0),\n",
       " ('severe acute respiratory syndrome coronavirus 2 sarscov2 disease', 1.0),\n",
       " ('reuse allow', 0.925),\n",
       " ('science', 0.925),\n",
       " ('pandemic spread', 0.734),\n",
       " ('rok bimodal distribution high morbidity', 0.707),\n",
       " ('standard gaussian distribution peak morbidity', 0.707),\n",
       " ('44 95 ci 39 49 generalize growth model', 0.707),\n",
       " ('estimate reproduction', 0.707),\n",
       " ('responsible current sarscov2', 0.707),\n",
       " ('zoonotic coronavirus cov infection', 0.707),\n",
       " ('1 inflammatory storm', 0.707),\n",
       " ('monocyte centric immune interaction 2 reveal singlecell analysis', 0.707),\n",
       " ('covid19 outbreak', 0.707),\n",
       " ('globally risk infection', 0.707),\n",
       " ('100 country report', 0.707),\n",
       " ('rapid global spread coronavirus disease covid19 unprecedented outbreak',\n",
       "  0.707),\n",
       " ('1 precipitation seasonality speed', 0.707),\n",
       " ('2 temperature', 0.707),\n",
       " ('clinical diagnosis treatment patient', 0.707),\n",
       " ('evidence covid19 infection human nervous system digestive system reproductive system respiratory system circulatory system urinary system scrnaseq',\n",
       "  0.707),\n",
       " ('complete genome sequence porcine epidemic diarrhea virus pedv strain chgx2015750a 750a isolate suckle piglet watery diarrhea guangxi china',\n",
       "  0.707),\n",
       " ('genetically close recent chinese variant pedvs distinct classical pedvs',\n",
       "  0.707),\n",
       " ('biology', 0.707),\n",
       " ('subject area ecologyhealth disease epidemiologymolecular biology', 0.707),\n",
       " ('cellular susceptibility fusion', 0.707),\n",
       " ('separate lipiddependent lipidindependent mechanism', 0.707),\n",
       " ('active viral protease inhibitor', 0.691),\n",
       " ('38 2008 s97s99', 0.691),\n",
       " ('immunology', 0.679),\n",
       " ('j gong e zhang b multiple organ infection pathogenesis', 0.679),\n",
       " ('perception experience', 0.676),\n",
       " ('public social distance social isolation measure', 0.676),\n",
       " ('3 generally long incubation serial interval', 0.653),\n",
       " ('epidemic absence appropriate control measure', 0.653),\n",
       " ('rapidly china world early surveillance public health 16 emergency disposal',\n",
       "  0.645),\n",
       " ('3c pro', 0.633),\n",
       " ('city china', 0.605),\n",
       " ('outbreak humantohuman', 0.605),\n",
       " ('diagnostic potential clinical impact', 0.605),\n",
       " ('respiratory panel', 0.605),\n",
       " ('activation irf3 pathway', 0.588),\n",
       " ('2019 novel coronavirus 2019ncov export mainland', 0.577),\n",
       " ('lead selfsustain outbreak population', 0.577),\n",
       " ('ongoing outbreak atypical pneumonia', 0.577),\n",
       " ('1 importance', 0.577),\n",
       " ('2 transmission', 0.577),\n",
       " ('highrisk occupation early coronavirus 4 disease 2019 covid19 local transmission',\n",
       "  0.577),\n",
       " ('development molecular syndromebased kit diagnosis respiratory infection',\n",
       "  0.577),\n",
       " ('rapid sensitive detection common respiratory pathogen 19 significant impact',\n",
       "  0.577),\n",
       " ('rural area', 0.577),\n",
       " ('43 tropism pathogenesis sarscov2', 0.577),\n",
       " ('application human organoids', 0.577),\n",
       " ('novel drug 44 discovery', 0.577),\n",
       " ('accurate secondary structure homolog consideration', 0.577),\n",
       " ('simultaneous consideration sequence alignment rna secondary structure structural alignment know help',\n",
       "  0.577),\n",
       " ('structural alignment', 0.577),\n",
       " ('pearson', 0.577),\n",
       " ('compute ratio daily death', 0.577),\n",
       " ('concern approach', 0.577),\n",
       " ('daily confirm infection b', 0.577),\n",
       " ('clear evidence apparent fatality rate', 0.577),\n",
       " ('death covid19 explanation', 0.577),\n",
       " ('vary different test regime admission', 0.577),\n",
       " ('public support containment measure', 0.577),\n",
       " ('quickly outbreak reduce exposure live animal', 0.577),\n",
       " ('wet market healthy diet promote', 0.577),\n",
       " ('collectively immune 40 available display', 0.577),\n",
       " ('effect social distance control impact covid19 epidemic simple susceptibleinfectedremoved epidemic model alternative complementary approach base target isolation vulnerable subpopulation',\n",
       "  0.577),\n",
       " ('efficient robust strategy low economic social cost short timeframe', 0.577),\n",
       " ('2008 1331s7s key word', 0.577),\n",
       " ('emergency mass critical care executive summary', 0.577),\n",
       " ('standard care', 0.577),\n",
       " ('production recombinant protein major success biotechnology animal cell',\n",
       "  0.577),\n",
       " ('protein appropriate posttranslational modification transgenic animal purpose milk egg white blood urine seminal plasma silk worm cocoon',\n",
       "  0.577),\n",
       " ('transgenic animal candidate source recombinant protein industrial scale',\n",
       "  0.577),\n",
       " ('c7 position', 0.577),\n",
       " ('chemmedchem compound', 0.577),\n",
       " ('low activity', 0.577),\n",
       " ('wet mount test', 0.569),\n",
       " ('bcv', 0.557),\n",
       " ('interferon gamma', 0.552),\n",
       " ('rationale', 0.548),\n",
       " ('sarscov2 outbreak low infection size', 0.548),\n",
       " ('widely discuss definite answer', 0.548),\n",
       " ('china mortality novel coronavirus pneumonia ncp severe critical face kind public health emergency efficient administrative emergency responsive mode',\n",
       "  0.547),\n",
       " ('hospital need', 0.547),\n",
       " ('ongoing sarscov2 outbreak', 0.543),\n",
       " ('pose great challenge global public health sensitive 21 accurate diagnosis method',\n",
       "  0.543),\n",
       " ('sicken', 0.543),\n",
       " ('concern possibility vertical transmission virus mother', 0.539),\n",
       " ('new coronavirus china', 0.539),\n",
       " ('necroptosis', 0.535),\n",
       " ('nurse', 0.535),\n",
       " ('nanotube', 0.531),\n",
       " ('honey bee', 0.53)]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tfidf_key_phrases(text_data_cleaned, top_n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens = []\n",
    "for doc in text_data_cleaned:\n",
    "    tokens = []\n",
    "    for t in tokenizer(doc):\n",
    "        if len(t.text) == 1 or len(list(set(t.text))) == 1:\n",
    "            pass\n",
    "        else:\n",
    "            tokens.append(t.text)\n",
    "    text_tokens.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['194', '5168', '23', '24', '25', 'reuse', 'allow', 'permission', '27', 'positive', 'strand', 'rna', 'genome', 'picornaviruses', 'comprise', 'single', 'large', 'open', 'read', '28', 'frame', 'flank', 'untranslated', 'region', 'utrs', 'footandmouth', 'disease', 'virus', 'fmdv', '29', 'unusually', 'large', 'utr', '13', 'kb', 'contain', 'structural', 'domain', 'include', '30', 'internal', 'ribosome', 'entry', 'site', 'ires', 'facilitate', 'initiation', 'translation', 'cisacting', '31', 'replication', 'element', 'cre', 'characterise', 'structure', 'terminal', '360', 'nucleotide', '32', 'stemloop', 'variable', 'length', 'polyctract', 'approximately', '100', '200', 'nucleotide', 'series', 'tandemly', 'repeat', 'pseudoknots', 'pk', 'investigate', 'structure', 'pk', '34', 'selective', 'hydroxyl', 'acetylation', 'analyse', 'primer', 'extension', 'shape', 'analysis', '35', 'determine', 'contribution', 'genome', 'replication', 'mutation', 'deletion', 'experiment', '36', 'shape', 'mutation', 'experiment', 'confirm', 'importance', 'previously', 'predict', 'pk', '37', 'structure', 'function', 'deletion', 'experiment', 'show', 'pk', 'essential', '38', 'replication', 'provide', 'genome', 'competitive', 'advantage', '39', 'replicons', 'fulllength', 'genome', 'lack', 'pk', 'replication', 'competent', 'infectious', '40', 'virus', 'rescue', 'genome', 'contain', 'pk', 'copy', 'consistent', '41', 'early', 'report', 'describe', 'presence', 'putative', 'package', 'signal', 'pk', 'region', '42', '43', 'reuse', 'allow', 'permission'], ['past', 'month', 'new', 'coronavirus', 'sarscov2', 'epidemic', 'grow', 'exponentially', 'affect', '100', 'thousand', 'people', 'worldwide', 'cause', 'enormous', 'distress', 'economy', 'society', 'affect', 'country', 'plethora', 'analysis', 'base', 'viral', 'sequence', 'publish', 'scientific', 'journal', 'nonpeer', 'review', 'channel', 'investigate', 'sarscov2', 'genetic', 'heterogeneity', 'spatiotemporal', 'dissemination', 'examine', 'genome', 'sequence', 'currently', 'available', 'assess', 'presence', 'sufficient', 'information', 'reliable', 'phylogenetic', 'phylogeographic', 'study', 'analysis', 'clearly', 'show', 'severe', 'limitation', 'present', 'light', 'find', 'consider', 'well', 'preliminary', 'hypothesisgenerating', 'need', 'avoid', 'stigmatization', 'base', 'partial', 'information', 'continue', 'concerted', 'effort', 'increase', 'quality', 'sequence', 'require', 'robust', 'trace', 'epidemic', '40', 'available', 'display']]\n"
     ]
    }
   ],
   "source": [
    "print(text_tokens[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(text_tokens, min_count=20, threshold=50,delimiter=b'_') # higher threshold fewer phrases.\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_corpus_bigrams = [bigram_model[doc] for doc in text_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample word to number mappings: [(0, '100'), (1, '13'), (2, '194'), (3, '200'), (4, '23'), (5, '24'), (6, '25'), (7, '27'), (8, '28'), (9, '29'), (10, '30'), (11, '31'), (12, '32'), (13, '34'), (14, '35')]\n",
      "Total Vocabulary Size: 15378\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(norm_corpus_bigrams)\n",
    "print('Sample word to number mappings:', list(dictionary.items())[:15])\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=3, no_above=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 2792\n"
     ]
    }
   ],
   "source": [
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus_bigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (24, 2), (50, 1), (56, 1), (68, 1), (85, 1), (99, 1), (100, 2), (101, 1), (102, 1), (103, 1), (104, 2), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 2), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 2), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1)]\n",
      "[('100', 1), ('analysis', 2), ('genome', 1), ('investigate', 1), ('presence', 1), ('show', 1), ('40_available', 1), ('affect', 2), ('assess', 1), ('available', 1), ('avoid', 1), ('base', 2), ('cause', 1), ('channel', 1), ('clearly', 1), ('consider', 1), ('continue', 1), ('coronavirus', 1), ('country', 1), ('currently', 1), ('display', 1), ('dissemination', 1), ('distress', 1), ('economy', 1), ('effort', 1), ('enormous', 1), ('epidemic', 2), ('examine', 1), ('exponentially', 1), ('find', 1), ('genetic', 1), ('grow', 1), ('heterogeneity', 1), ('increase', 1), ('information', 2), ('journal', 1), ('light', 1), ('limitation', 1), ('month', 1), ('need', 1), ('new', 1), ('partial', 1), ('past', 1), ('people', 1), ('phylogenetic', 1), ('preliminary', 1), ('present', 1), ('publish', 1), ('quality', 1), ('reliable', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(bow_corpus[1][:50])\n",
    "print([(dictionary[idx],frequency) for idx,frequency in bow_corpus[1][:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers 1774\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of papers\",len(bow_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_TOPICS = 10\n",
    "lda_model = gensim.models.LdaModel(corpus=bow_corpus, id2word=dictionary,chunksize=1740, alpha='auto',eta='auto', random_state=42,\n",
    "                                    iterations=500, num_topics=TOTAL_TOPICS,passes=20, eval_every=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "0.016*\"system\" + 0.014*\"de\" + 0.011*\"development\" + 0.009*\"model\" + 0.009*\"la\" + 0.009*\"clinical\" + 0.009*\"provide\" + 0.008*\"approach\" + 0.008*\"design\" + 0.007*\"trial\" + 0.007*\"process\" + 0.007*\"network\" + 0.006*\"propose\" + 0.006*\"describe\" + 0.006*\"analysis\" + 0.006*\"need\" + 0.005*\"critical\" + 0.005*\"method\" + 0.005*\"develope\" + 0.005*\"information\"\n",
      "\n",
      "Topic #2:\n",
      "0.021*\"virus\" + 0.018*\"protein\" + 0.015*\"cell\" + 0.011*\"viral\" + 0.011*\"human\" + 0.009*\"infection\" + 0.008*\"host\" + 0.008*\"sarscov2\" + 0.007*\"coronavirus\" + 0.006*\"rna\" + 0.005*\"identify\" + 0.005*\"bind\" + 0.005*\"sequence\" + 0.005*\"result\" + 0.005*\"bat\" + 0.005*\"expression\" + 0.004*\"gene\" + 0.004*\"genome\" + 0.004*\"show\" + 0.004*\"target\"\n",
      "\n",
      "Topic #3:\n",
      "0.023*\"disease\" + 0.013*\"infection\" + 0.011*\"sarscov2\" + 0.010*\"transmission\" + 0.010*\"model\" + 0.010*\"outbreak\" + 0.007*\"individual\" + 0.006*\"infect\" + 0.006*\"spread\" + 0.005*\"covid19\" + 0.005*\"new\" + 0.005*\"virus\" + 0.005*\"result\" + 0.005*\"test\" + 0.005*\"risk\" + 0.005*\"viral\" + 0.004*\"health\" + 0.004*\"early\" + 0.004*\"human\" + 0.004*\"day\"\n",
      "\n",
      "Topic #4:\n",
      "0.043*\"patient\" + 0.026*\"covid19\" + 0.012*\"age\" + 0.012*\"infection\" + 0.012*\"clinical\" + 0.010*\"disease\" + 0.009*\"high\" + 0.009*\"95_ci\" + 0.008*\"rate\" + 0.008*\"group\" + 0.008*\"sarscov2\" + 0.008*\"year\" + 0.008*\"severe\" + 0.007*\"risk\" + 0.006*\"coronavirus\" + 0.006*\"include\" + 0.006*\"day\" + 0.006*\"factor\" + 0.006*\"respiratory\" + 0.006*\"death\"\n",
      "\n",
      "Topic #5:\n",
      "0.038*\"test\" + 0.020*\"ct\" + 0.018*\"covid19\" + 0.017*\"diagnosis\" + 0.014*\"patient\" + 0.013*\"pneumonia\" + 0.013*\"clinical\" + 0.012*\"positive\" + 0.010*\"image\" + 0.009*\"child\" + 0.009*\"study\" + 0.008*\"chest\" + 0.007*\"scan\" + 0.007*\"prevalence\" + 0.007*\"crp\" + 0.007*\"diagnostic\" + 0.007*\"review\" + 0.007*\"treatment\" + 0.007*\"sensitivity\" + 0.006*\"pool\"\n",
      "\n",
      "Topic #6:\n",
      "0.030*\"cell\" + 0.019*\"drug\" + 0.011*\"treatment\" + 0.011*\"activity\" + 0.010*\"inhibitor\" + 0.010*\"antiviral\" + 0.008*\"antibody\" + 0.008*\"compound\" + 0.007*\"sarscov2\" + 0.007*\"expression\" + 0.007*\"potential\" + 0.007*\"result\" + 0.006*\"target\" + 0.006*\"therapy\" + 0.006*\"vitro\" + 0.006*\"therapeutic\" + 0.006*\"covid19\" + 0.006*\"pro\" + 0.006*\"development\" + 0.005*\"inhibit\"\n",
      "\n",
      "Topic #7:\n",
      "0.041*\"model\" + 0.023*\"epidemic\" + 0.018*\"estimate\" + 0.018*\"covid19\" + 0.015*\"outbreak\" + 0.013*\"china\" + 0.013*\"spread\" + 0.010*\"report\" + 0.009*\"parameter\" + 0.009*\"infection\" + 0.009*\"predict\" + 0.009*\"rate\" + 0.009*\"day\" + 0.008*\"dynamic\" + 0.008*\"transmission\" + 0.008*\"country\" + 0.008*\"2020\" + 0.007*\"prediction\" + 0.007*\"result\" + 0.007*\"method\"\n",
      "\n",
      "Topic #8:\n",
      "0.042*\"antibody\" + 0.022*\"serum\" + 0.020*\"vaccine\" + 0.015*\"calve\" + 0.015*\"mouse\" + 0.012*\"woman\" + 0.010*\"influenza\" + 0.010*\"titer\" + 0.009*\"pregnancy\" + 0.009*\"strain\" + 0.009*\"zika\" + 0.008*\"elisa\" + 0.008*\"day\" + 0.008*\"result\" + 0.008*\"assay\" + 0.008*\"inactivate\" + 0.007*\"dengue\" + 0.007*\"feed\" + 0.007*\"seroconversion\" + 0.006*\"rbd\"\n",
      "\n",
      "Topic #9:\n",
      "0.016*\"country\" + 0.013*\"covid19\" + 0.010*\"strategy\" + 0.010*\"social\" + 0.009*\"pandemic\" + 0.009*\"policy\" + 0.009*\"measure\" + 0.009*\"reduce\" + 0.008*\"isolation\" + 0.008*\"contact\" + 0.008*\"death\" + 0.008*\"public_health\" + 0.007*\"intervention\" + 0.007*\"rate\" + 0.007*\"health\" + 0.007*\"individual\" + 0.007*\"healthcare\" + 0.007*\"state\" + 0.006*\"increase\" + 0.006*\"different\"\n",
      "\n",
      "Topic #10:\n",
      "0.021*\"virus\" + 0.019*\"sequence\" + 0.018*\"sample\" + 0.014*\"rna\" + 0.012*\"gene\" + 0.012*\"detect\" + 0.011*\"viral\" + 0.011*\"assay\" + 0.010*\"method\" + 0.010*\"detection\" + 0.009*\"mutation\" + 0.007*\"pathogen\" + 0.007*\"rate\" + 0.007*\"dna\" + 0.006*\"strain\" + 0.006*\"test\" + 0.006*\"genome\" + 0.006*\"host\" + 0.006*\"type\" + 0.005*\"result\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic in lda_model.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg coherence score:  -2.515884063670638\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "topics_coherences = lda_model.top_topics(bow_corpus,topn=20)\n",
    "avg_coherence_score = np.mean([score[1] for score in topics_coherences])\n",
    "print(\"avg coherence score: \",avg_coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics with Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "[('model', 0.041), ('epidemic', 0.023), ('estimate', 0.018), ('covid19', 0.018), ('outbreak', 0.015), ('china', 0.013), ('spread', 0.013), ('report', 0.01), ('parameter', 0.009), ('infection', 0.009), ('predict', 0.009), ('rate', 0.009), ('day', 0.009), ('dynamic', 0.008), ('transmission', 0.008), ('country', 0.008), ('2020', 0.008), ('prediction', 0.007), ('result', 0.007), ('method', 0.007)]\n",
      "\n",
      "Topic #2:\n",
      "[('disease', 0.023), ('infection', 0.013), ('sarscov2', 0.011), ('transmission', 0.01), ('model', 0.01), ('outbreak', 0.01), ('individual', 0.007), ('infect', 0.006), ('spread', 0.006), ('covid19', 0.005), ('new', 0.005), ('virus', 0.005), ('result', 0.005), ('test', 0.005), ('risk', 0.005), ('viral', 0.005), ('health', 0.004), ('early', 0.004), ('human', 0.004), ('day', 0.004)]\n",
      "\n",
      "Topic #3:\n",
      "[('virus', 0.021), ('protein', 0.018), ('cell', 0.015), ('viral', 0.011), ('human', 0.011), ('infection', 0.009), ('host', 0.008), ('sarscov2', 0.008), ('coronavirus', 0.007), ('rna', 0.006), ('identify', 0.005), ('bind', 0.005), ('sequence', 0.005), ('result', 0.005), ('bat', 0.005), ('expression', 0.005), ('gene', 0.004), ('genome', 0.004), ('show', 0.004), ('target', 0.004)]\n",
      "\n",
      "Topic #4:\n",
      "[('patient', 0.043), ('covid19', 0.026), ('age', 0.012), ('infection', 0.012), ('clinical', 0.012), ('disease', 0.01), ('high', 0.009), ('95_ci', 0.009), ('rate', 0.008), ('group', 0.008), ('sarscov2', 0.008), ('year', 0.008), ('severe', 0.008), ('risk', 0.007), ('coronavirus', 0.006), ('include', 0.006), ('day', 0.006), ('factor', 0.006), ('respiratory', 0.006), ('death', 0.006)]\n",
      "\n",
      "Topic #5:\n",
      "[('virus', 0.021), ('sequence', 0.019), ('sample', 0.018), ('rna', 0.014), ('gene', 0.012), ('detect', 0.012), ('viral', 0.011), ('assay', 0.011), ('method', 0.01), ('detection', 0.01), ('mutation', 0.009), ('pathogen', 0.007), ('rate', 0.007), ('dna', 0.007), ('strain', 0.006), ('test', 0.006), ('genome', 0.006), ('host', 0.006), ('type', 0.006), ('result', 0.005)]\n",
      "\n",
      "Topic #6:\n",
      "[('country', 0.016), ('covid19', 0.013), ('strategy', 0.01), ('social', 0.01), ('pandemic', 0.009), ('policy', 0.009), ('measure', 0.009), ('reduce', 0.009), ('isolation', 0.008), ('contact', 0.008), ('death', 0.008), ('public_health', 0.008), ('intervention', 0.007), ('rate', 0.007), ('health', 0.007), ('individual', 0.007), ('healthcare', 0.007), ('state', 0.007), ('increase', 0.006), ('different', 0.006)]\n",
      "\n",
      "Topic #7:\n",
      "[('cell', 0.03), ('drug', 0.019), ('treatment', 0.011), ('activity', 0.011), ('inhibitor', 0.01), ('antiviral', 0.01), ('antibody', 0.008), ('compound', 0.008), ('sarscov2', 0.007), ('expression', 0.007), ('potential', 0.007), ('result', 0.007), ('target', 0.006), ('therapy', 0.006), ('vitro', 0.006), ('therapeutic', 0.006), ('covid19', 0.006), ('pro', 0.006), ('development', 0.006), ('inhibit', 0.005)]\n",
      "\n",
      "Topic #8:\n",
      "[('test', 0.038), ('ct', 0.02), ('covid19', 0.018), ('diagnosis', 0.017), ('patient', 0.014), ('pneumonia', 0.013), ('clinical', 0.013), ('positive', 0.012), ('image', 0.01), ('child', 0.009), ('study', 0.009), ('chest', 0.008), ('scan', 0.007), ('prevalence', 0.007), ('crp', 0.007), ('diagnostic', 0.007), ('review', 0.007), ('treatment', 0.007), ('sensitivity', 0.007), ('pool', 0.006)]\n",
      "\n",
      "Topic #9:\n",
      "[('system', 0.016), ('de', 0.014), ('development', 0.011), ('model', 0.009), ('la', 0.009), ('clinical', 0.009), ('provide', 0.009), ('approach', 0.008), ('design', 0.008), ('trial', 0.007), ('process', 0.007), ('network', 0.007), ('propose', 0.006), ('describe', 0.006), ('analysis', 0.006), ('need', 0.006), ('critical', 0.005), ('method', 0.005), ('develope', 0.005), ('information', 0.005)]\n",
      "\n",
      "Topic #10:\n",
      "[('antibody', 0.042), ('serum', 0.022), ('vaccine', 0.02), ('calve', 0.015), ('mouse', 0.015), ('woman', 0.012), ('influenza', 0.01), ('titer', 0.01), ('pregnancy', 0.009), ('strain', 0.009), ('zika', 0.009), ('elisa', 0.008), ('day', 0.008), ('result', 0.008), ('assay', 0.008), ('inactivate', 0.008), ('dengue', 0.007), ('feed', 0.007), ('seroconversion', 0.007), ('rbd', 0.006)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics_with_wts = [item[0] for item in topics_coherences]\n",
    "print('LDA Topics with Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([(term, round(wt, 3)) for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics without Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "['model', 'epidemic', 'estimate', 'covid19', 'outbreak', 'china', 'spread', 'report', 'parameter', 'infection', 'predict', 'rate', 'day', 'dynamic', 'transmission', 'country', '2020', 'prediction', 'result', 'method']\n",
      "\n",
      "Topic #2:\n",
      "['disease', 'infection', 'sarscov2', 'transmission', 'model', 'outbreak', 'individual', 'infect', 'spread', 'covid19', 'new', 'virus', 'result', 'test', 'risk', 'viral', 'health', 'early', 'human', 'day']\n",
      "\n",
      "Topic #3:\n",
      "['virus', 'protein', 'cell', 'viral', 'human', 'infection', 'host', 'sarscov2', 'coronavirus', 'rna', 'identify', 'bind', 'sequence', 'result', 'bat', 'expression', 'gene', 'genome', 'show', 'target']\n",
      "\n",
      "Topic #4:\n",
      "['patient', 'covid19', 'age', 'infection', 'clinical', 'disease', 'high', '95_ci', 'rate', 'group', 'sarscov2', 'year', 'severe', 'risk', 'coronavirus', 'include', 'day', 'factor', 'respiratory', 'death']\n",
      "\n",
      "Topic #5:\n",
      "['virus', 'sequence', 'sample', 'rna', 'gene', 'detect', 'viral', 'assay', 'method', 'detection', 'mutation', 'pathogen', 'rate', 'dna', 'strain', 'test', 'genome', 'host', 'type', 'result']\n",
      "\n",
      "Topic #6:\n",
      "['country', 'covid19', 'strategy', 'social', 'pandemic', 'policy', 'measure', 'reduce', 'isolation', 'contact', 'death', 'public_health', 'intervention', 'rate', 'health', 'individual', 'healthcare', 'state', 'increase', 'different']\n",
      "\n",
      "Topic #7:\n",
      "['cell', 'drug', 'treatment', 'activity', 'inhibitor', 'antiviral', 'antibody', 'compound', 'sarscov2', 'expression', 'potential', 'result', 'target', 'therapy', 'vitro', 'therapeutic', 'covid19', 'pro', 'development', 'inhibit']\n",
      "\n",
      "Topic #8:\n",
      "['test', 'ct', 'covid19', 'diagnosis', 'patient', 'pneumonia', 'clinical', 'positive', 'image', 'child', 'study', 'chest', 'scan', 'prevalence', 'crp', 'diagnostic', 'review', 'treatment', 'sensitivity', 'pool']\n",
      "\n",
      "Topic #9:\n",
      "['system', 'de', 'development', 'model', 'la', 'clinical', 'provide', 'approach', 'design', 'trial', 'process', 'network', 'propose', 'describe', 'analysis', 'need', 'critical', 'method', 'develope', 'information']\n",
      "\n",
      "Topic #10:\n",
      "['antibody', 'serum', 'vaccine', 'calve', 'mouse', 'woman', 'influenza', 'titer', 'pregnancy', 'strain', 'zika', 'elisa', 'day', 'result', 'assay', 'inactivate', 'dengue', 'feed', 'seroconversion', 'rbd']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('LDA Topics without Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
